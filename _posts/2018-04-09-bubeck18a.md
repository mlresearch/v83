---
title: Sparsity, variance and curvature in multi-armed bandits
abstract: 'In (online) learning theory the concepts of sparsity, variance and curvature
  are well-understood and are routinely used to obtain refined regret and generalization
  bounds. In this paper we further our understanding of these concepts in the more
  challenging limited feedback scenario. We consider the adversarial multi-armed bandit
  and linear bandit settings and solve several open problems pertaining to the existence
  of algorithms with favorable regret bounds under the following assumptions: (i)
  sparsity of the individual losses, (ii) small variation of the loss sequence, and
  (iii) curvature of the action set. Specifically we show that (i) for $s$-sparse
  losses one can obtain $\tilde{O}(\sqrt{s T})$-regret (solving an open problem by
  Kwon and Perchet), (ii) for loss sequences with variation bounded by $Q$ one can
  obtain $\tilde{O}(\sqrt{Q})$-regret (solving an open problem by Kale and Hazan),
  and (iii) for linear bandit on an $\ell_p^n$ ball one can obtain $\tilde{O}(\sqrt{n
  T})$-regret for $p ∈[1,2]$ and one has $\tilde{Ω}(n \sqrt{T})$-regret for $p>2$
  (solving an open problem by Bubeck, Cesa-Bianchi and Kakade). A key new insight
  to obtain these results is to use regularizers satisfying more refined conditions
  than general self-concordance.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: bubeck18a
month: 0
tex_title: Sparsity, variance and curvature in multi-armed bandits
firstpage: 111
lastpage: 127
page: 111-127
order: 111
cycles: false
author:
- given: Sébastien
  family: Bubeck
- given: Michael
  family: Cohen
- given: Yuanzhi
  family: Li
date: 2018-04-09
address: 
publisher: PMLR
container-title: Proceedings of Algorithmic Learning Theory
volume: '83'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 4
  - 9
pdf: http://proceedings.mlr.press/v83/bubeck18a/bubeck18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
