---
title: Markov Decision Processes with Continuous Side Information
abstract: " We consider a reinforcement learning (RL) setting in which the agent interacts
  with a sequence of episodic MDPs. At the start of each episode the agent has access
  to some side-information or context that determines the dynamics of the MDP for
  that episode. Our setting is motivated by applications in healthcare where baseline
  measurements of a patient at the start of a treatment episode form the context that
  may provide information about how the patient might respond to treatment decisions.
  \r We propose algorithms for learning in such Contextual Markov Decision Processes
  (CMDPs) under an assumption that the unobserved MDP parameters vary smoothly with
  the observed context. We give lower and upper PAC bounds under the smoothness assumption.
  Because our lower bound has an exponential dependence on the dimension, we also
  consider a tractable linear setting where the context creates linear combinations
  of a finite set of MDPs. For the linear setting, we give a PAC learning algorithm
  based on KWIK learning techniques."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: modi18a
month: 0
tex_title: Markov Decision Processes with Continuous Side Information
firstpage: 597
lastpage: 618
page: 597-618
order: 597
cycles: false
author:
- given: Aditya
  family: Modi
- given: Nan
  family: Jiang
- given: Satinder
  family: Singh
- given: Ambuj
  family: Tewari
date: 2018-04-09
address: 
publisher: PMLR
container-title: Proceedings of Algorithmic Learning Theory
volume: '83'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 4
  - 9
pdf: http://proceedings.mlr.press/v83/modi18a/modi18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
