---
title: Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence
abstract: We consider the problem of near-optimal arm identification in the fixed
  confidence setting of the infinitely armed bandit problem when nothing is known
  about the arm reservoir distribution. We (1) introduce a PAC-like framework within
  which to derive and cast results; (2) derive a sample complexity lower bound for
  near-optimal arm identification; (3) propose an algorithm that identifies a nearly-optimal
  arm with high probability and derive an upper bound on its sample complexity which
  is within a log factor of our lower bound; and (4) discuss whether our $\log^2 \frac{1}{δ}$
  dependence is inescapable for “two-phase” (select arms first, identify the best
  later) algorithms in the infinite setting. This work permits the application of
  bandit models to a broader class of problems where fewer assumptions hold.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: aziz18a
month: 0
tex_title: Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence
firstpage: 3
lastpage: 24
page: 3-24
order: 3
cycles: false
author:
- given: Maryam
  family: Aziz
- given: Jesse
  family: Anderton
- given: Emilie
  family: Kaufmann
- given: Javed
  family: Aslam
date: 2018-04-09
address: 
publisher: PMLR
container-title: Proceedings of Algorithmic Learning Theory
volume: '83'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 4
  - 9
pdf: http://proceedings.mlr.press/v83/aziz18a/aziz18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
