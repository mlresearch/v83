---
title: Convergence of Langevin MCMC in KL-divergence
abstract: Langevin diffusion is a commonly used tool for sampling from a given distribution.
  In this work, we establish that when the target density $\p^*$ is such that $\log
  \p^*$ is $L$ smooth and $m$ strongly convex, discrete Langevin diffusion produces
  a distribution $\p$ with $\KL{\p}{\p^*}≤ε$ in $\tilde{O}(\frac{d}{ε})$ steps, where
  $d$ is the dimension of the sample space.  We also study the convergence rate when
  the strong-convexity assumption is absent. By considering the Langevin diffusion
  as a gradient flow in the space of probability distributions, we obtain an elegant
  analysis that applies to the stronger property of convergence in KL-divergence and
  gives a conceptually simpler proof of the best-known convergence results in weaker
  metrics.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cheng18a
month: 0
tex_title: Convergence of Langevin MCMC in KL-divergence
firstpage: 186
lastpage: 211
page: 186-211
order: 186
cycles: false
author:
- given: Xiang
  family: Cheng
- given: Peter
  family: Bartlett
date: 2018-04-09
address: 
publisher: PMLR
container-title: Proceedings of Algorithmic Learning Theory
volume: '83'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 4
  - 9
pdf: http://proceedings.mlr.press/v83/cheng18a/cheng18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
